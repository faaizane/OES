from flask import Flask, request, jsonify
from flask_cors import CORS
from dotenv import load_dotenv
import os, torch, jwt, time, threading, collections, base64, gc
import numpy as np, mediapipe as mp, requests, io, imageio, math, warnings, cv2
import psutil
from functools import lru_cache

# ── Load .env ───────────────────────────────
load_dotenv()
SECRET       = os.getenv('JWT_SECRET')
NODE_BACKEND = os.getenv('NODE_BACKEND', '').rstrip('/')
FFMPEG_PATH  = os.getenv('FFMPEG_PATH')

if not SECRET or not NODE_BACKEND:
    raise RuntimeError("JWT_SECRET or NODE_BACKEND not set in .env")

# suppress warnings for cleaner logs
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

# ── Ensure FFmpeg for imageio ───────────────
if FFMPEG_PATH and os.path.isfile(FFMPEG_PATH):
    os.environ['PATH'] += os.pathsep + os.path.dirname(FFMPEG_PATH)
    os.environ['IMAGEIO_FFMPEG_EXE'] = FFMPEG_PATH
else:
    try:
        import imageio.plugins.ffmpeg as ffmpeg_plugin
        ffmpeg_plugin.download()
    except Exception:
        print("⚠️ Warning: FFmpeg not found or auto-download failed; ensure it's on PATH.")

app = Flask(__name__)
CORS(app)

# ── Load YOLOv5 with Railway optimization ─────────────────────────────
print("🔄 Loading YOLOv5 model...")
try:
    # Use smaller model for better performance on limited resources
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, force_reload=False, verbose=False)
    model.conf, model.iou = 0.6, 0.45  # Increased confidence for better accuracy
    
    # Optimize model for inference
    model.eval()
    if hasattr(model, 'fuse'):
        model.fuse()
    
    # Warm up the model
    dummy_input = torch.zeros((1, 3, 640, 640))
    with torch.no_grad():
        _ = model(dummy_input)
    
    print("✅ YOLOv5 model loaded successfully")
except Exception as e:
    print(f"❌ Error loading YOLOv5: {e}")
    raise e

# ── MediaPipe Face Mesh with caching ─────────────────────
mp_face = mp.solutions.face_mesh

@lru_cache(maxsize=10)
def create_face_mesh():
    """Create face mesh with caching"""
    return mp_face.FaceMesh(
        static_image_mode=False,  # Better for video streams
        max_num_faces=2,
        refine_landmarks=True,
        min_detection_confidence=0.6,  # Increased for better accuracy
        min_tracking_confidence=0.5
    )

# Store face mesh instances per student
face_mesh_instances = {}

# ── Globals & counters ──────────────────────
CHEAT_LOCK = threading.Lock()
cheated_recently = {}

# Per-student counters
student_counters = {}

# ── Optimized Thresholds for Railway ─────────────────────────────
NO_FACE_FRAMES       = 8      # Increased for stability
MULTI_FACE_FRAMES    = 8       # Increased for stability  
HEAD_TURN_FRAMES     = 5      # Increased for stability
HEAD_TURN_ANGLE      = 30      # Slightly more lenient
OBJ_DET_FRAMES       = 4       # Increased for stability
GAZE_FRAMES          = 5      # Increased for stability
PHONE_FRAMES         = 4       # Increased for stability
PHONE_CONF_THRESH    = 0.5     # Higher confidence for phones
GAZE_RATIO_MIN       = 0.35    # Slightly more lenient
GAZE_RATIO_MAX       = 0.65    # Slightly more lenient
OBJECT_CLASSES       = ['laptop', 'book', 'tablet', 'remote']

def get_student_counters(student_id):
    """Get or create counters for a specific student"""
    if student_id not in student_counters:
        student_counters[student_id] = {
            'NO_FACE_COUNTER': 0,
            'MULTI_FACE_COUNTER': 0,
            'HEAD_TURN_COUNTER': 0,
            'GAZE_COUNTER': 0,
            'OBJECT_COUNTER': 0,
            'PHONE_COUNTER': 0,
            'FRAME_BUFFER': collections.deque(maxlen=100),  # Reduced buffer size
            'LAST_PROCESSED': time.time()
        }
    
    # Create face mesh instance for this student if not exists
    if student_id not in face_mesh_instances:
        face_mesh_instances[student_id] = create_face_mesh()
    
    return student_counters[student_id]

def head_pose(landmarks):
    """Calculate head pose angle"""
    try:
        l, r = landmarks[33], landmarks[263]
        return math.degrees(math.atan2(r.y - l.y, r.x - l.x))
    except (IndexError, AttributeError):
        return 0

def cleanup_resources():
    """Clean up resources periodically"""
    try:
        gc.collect()
        # Log memory usage
        memory = psutil.virtual_memory()
        print(f"📊 Memory usage: {memory.percent}%")
    except Exception:
        pass

def handle_cheat(student_id, exam_id, token_header, reason):
    """Handle cheat detection and upload video clip"""
    student_key = f"{student_id}_{exam_id}"
    
    # Check if already processing cheat for this student
    with CHEAT_LOCK:
        if cheated_recently.get(student_key, False):
            return
        cheated_recently[student_key] = True
    
    try:
        counters = get_student_counters(student_id)
        frames = list(counters['FRAME_BUFFER'])
        
        if not frames:
            return

        # Create video with reduced quality for faster upload
        buf = io.BytesIO()
        writer = imageio.get_writer(buf, format='mp4', mode='I', fps=15, quality=5)  # Reduced quality
        
        # Sample frames to reduce video size
        frame_step = max(1, len(frames) // 30)  # Max 30 frames
        for i in range(0, len(frames), frame_step):
            frame = frames[i]
            # Resize frame to reduce size
            height, width = frame.shape[:2]
            new_width = min(640, width)
            new_height = int(height * (new_width / width))
            resized_frame = cv2.resize(frame, (new_width, new_height))
            rgb = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)
            writer.append_data(rgb)
        
        writer.close()
        buf.seek(0)
        clip_data = buf.read()
        buf.close()

        print(f"📤 Uploading cheat evidence for student {student_id}: {reason}")
        resp = requests.post(
            f'{NODE_BACKEND}/api/cheats',
            files={'clip': ('cheat.mp4', clip_data, 'video/mp4')},
            data={'studentId': student_id, 'examId': exam_id, 'reason': reason},
            headers={'Authorization': token_header},
            timeout=15
        )
        print(f"✅ [handle_cheat] POST /api/cheats → {resp.status_code}")
        
    except Exception as e:
        print(f"❌ Cheat upload error: {e}")
    finally:
        time.sleep(1)  # Reduced delay
        with CHEAT_LOCK:
            cheated_recently[student_key] = False

def process_frame(student_id, exam_id, token_header, frame_data):
    """Process a single frame for AI detection with optimizations"""
    student_key = f"{student_id}_{exam_id}"
    counters = get_student_counters(student_id)
    
    # Rate limiting - process every 2nd frame for performance
    current_time = time.time()
    if current_time - counters['LAST_PROCESSED'] < 0.1:  # 100ms throttle
        return {"status": "throttled"}
    
    counters['LAST_PROCESSED'] = current_time
    
    # Check if already processing cheat for this student
    with CHEAT_LOCK:
        if cheated_recently.get(student_key, False):
            return {"status": "processing"}
    
    try:
        # Decode base64 frame
        frame_bytes = base64.b64decode(frame_data.split(',')[1])
        nparr = np.frombuffer(frame_bytes, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if frame is None:
            return {"status": "error", "message": "Invalid frame data"}
        
        # Resize frame for faster processing
        height, width = frame.shape[:2]
        if width > 640:
            new_width = 640
            new_height = int(height * (new_width / width))
            frame = cv2.resize(frame, (new_width, new_height))
        
        counters['FRAME_BUFFER'].append(frame.copy())
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # Get student-specific face mesh instance
        student_face_mesh = face_mesh_instances[student_id]
        
        # Process with MediaPipe face detection
        try:
            mp_res = student_face_mesh.process(rgb)
        except Exception as mp_error:
            print(f"MediaPipe processing error for student {student_id}: {mp_error}")
            # Create a new face mesh instance if there's an error
            face_mesh_instances[student_id] = create_face_mesh()
            return {"status": "error", "message": "MediaPipe processing failed"}

        # ── Face checks ────────────────────────
        if mp_res.multi_face_landmarks:
            counters['NO_FACE_COUNTER'] = 0

            # Multiple faces check
            if len(mp_res.multi_face_landmarks) > 1:
                counters['MULTI_FACE_COUNTER'] += 1
            else:
                counters['MULTI_FACE_COUNTER'] = 0
                
            if counters['MULTI_FACE_COUNTER'] >= MULTI_FACE_FRAMES:
                counters['MULTI_FACE_COUNTER'] = 0
                print(f"🚨 CHEAT DETECTED: Multiple faces - Student {student_id}")
                threading.Thread(
                    target=handle_cheat,
                    args=(student_id, exam_id, token_header, "Multiple faces detected"),
                    daemon=True
                ).start()
                return {"status": "cheat_detected", "reason": "Multiple faces detected"}

            # Head pose and gaze detection
            try:
                lm = mp_res.multi_face_landmarks[0].landmark
                angle = head_pose(lm)
                
                counters['HEAD_TURN_COUNTER'] = counters['HEAD_TURN_COUNTER'] + 1 if abs(angle) > HEAD_TURN_ANGLE else 0
                if counters['HEAD_TURN_COUNTER'] >= HEAD_TURN_FRAMES:
                    print(f"🚨 CHEAT DETECTED: Head turned away - Student {student_id}, Angle: {angle:.1f}°")
                    threading.Thread(
                        target=handle_cheat,
                        args=(student_id, exam_id, token_header, "Head turned away"),
                        daemon=True
                    ).start()
                    counters['HEAD_TURN_COUNTER'] = 0
                    return {"status": "cheat_detected", "reason": "Head turned away"}

                # Gaze detection with error handling
                try:
                    iris = [lm[i] for i in (468,469,470,471)]
                    left_x, right_x = min(p.x for p in iris), max(p.x for p in iris)
                    ratio = ((left_x+right_x)/2 - lm[33].x) / (lm[133].x - lm[33].x + 1e-6)
                    
                    counters['GAZE_COUNTER'] = counters['GAZE_COUNTER']+1 if (ratio<GAZE_RATIO_MIN or ratio>GAZE_RATIO_MAX) else 0
                    if counters['GAZE_COUNTER'] >= GAZE_FRAMES:
                        print(f"🚨 CHEAT DETECTED: Gaze averted - Student {student_id}, Ratio: {ratio:.3f}")
                        threading.Thread(
                            target=handle_cheat,
                            args=(student_id, exam_id, token_header, "Gaze averted"),
                            daemon=True
                        ).start()
                        counters['GAZE_COUNTER'] = 0
                        return {"status": "cheat_detected", "reason": "Gaze averted"}
                except (IndexError, AttributeError):
                    # Skip gaze detection if landmarks are insufficient
                    pass

            except (IndexError, AttributeError) as e:
                print(f"Error in pose/gaze detection: {e}")

        else:
            counters['MULTI_FACE_COUNTER'] = 0
            counters['NO_FACE_COUNTER'] += 1
            if counters['NO_FACE_COUNTER'] >= NO_FACE_FRAMES:
                print(f"🚨 CHEAT DETECTED: No face detected - Student {student_id}")
                threading.Thread(
                    target=handle_cheat,
                    args=(student_id, exam_id, token_header, "No face detected"),
                    daemon=True
                ).start()
                counters['NO_FACE_COUNTER'] = 0
                return {"status": "cheat_detected", "reason": "No face detected"}

        # ── Object & phone detection with optimization ─────────────
        try:
            with torch.no_grad():
                results = model(rgb, size=416)  # Reduced size for faster processing

            # Phone detection
            phone_seen = False
            for *_, conf, cls in results.xyxy[0]:
                if results.names[int(cls)] == 'cell phone' and conf >= PHONE_CONF_THRESH:
                    counters['PHONE_COUNTER'] += 1
                    phone_seen = True
                    break
                    
            if not phone_seen:
                counters['PHONE_COUNTER'] = 0

            if counters['PHONE_COUNTER'] >= PHONE_FRAMES:
                counters['PHONE_COUNTER'] = 0
                print(f"🚨 CHEAT DETECTED: Cell phone - Student {student_id}")
                threading.Thread(
                    target=handle_cheat,
                    args=(student_id, exam_id, token_header, "Cell phone"),
                    daemon=True
                ).start()
                return {"status": "cheat_detected", "reason": "Cell phone"}

            # Generic objects
            found, lbl = False, None
            for *_, conf, cls in results.xyxy[0]:
                class_name = results.names[int(cls)]
                if class_name in OBJECT_CLASSES and conf >= 0.5:
                    found, lbl = True, class_name
                    break

            counters['OBJECT_COUNTER'] = counters['OBJECT_COUNTER']+1 if found else 0
            if counters['OBJECT_COUNTER'] >= OBJ_DET_FRAMES:
                counters['OBJECT_COUNTER'] = 0
                print(f"🚨 CHEAT DETECTED: Object detected - Student {student_id}, Object: {lbl}")
                threading.Thread(
                    target=handle_cheat,
                    args=(student_id, exam_id, token_header, lbl.capitalize()),
                    daemon=True
                ).start()
                return {"status": "cheat_detected", "reason": f"Object detected: {lbl}"}

        except Exception as yolo_error:
            print(f"YOLO processing error: {yolo_error}")

        # Periodic cleanup
        if hasattr(process_frame, '_frame_count'):
            process_frame._frame_count += 1
        else:
            process_frame._frame_count = 1
            
        if process_frame._frame_count % 50 == 0:  # Every 50 frames
            cleanup_resources()

        return {"status": "success"}
        
    except Exception as e:
        print(f"Frame processing error: {e}")
        return {"status": "error", "message": str(e)}

@app.route('/process_frame', methods=['POST'])
def process_frame_endpoint():
    """API endpoint to process a single frame"""
    try:
        data = request.get_json()
        raw = data.get('token')
        exam_id = data.get('exam')
        frame_data = data.get('frame')
        
        if not raw or not exam_id or not frame_data:
            return jsonify({"error": "Missing required parameters"}), 400

        token = raw.split()[-1] if raw.startswith('Bearer ') else raw
        try:
            payload = jwt.decode(token, SECRET, algorithms=['HS256'])
            student_id = payload['userId']
        except jwt.ExpiredSignatureError:
            return jsonify({"error": "Token expired"}), 401
        except Exception:
            return jsonify({"error": "Invalid token"}), 401

        bearer = raw if raw.startswith('Bearer ') else f"Bearer {token}"
        result = process_frame(student_id, exam_id, bearer, frame_data)
        
        return jsonify(result)
        
    except Exception as e:
        print(f"Process frame endpoint error: {e}")
        return jsonify({"error": "Internal server error"}), 500

@app.route('/status', methods=['GET'])
def status():
    """Health check endpoint"""
    try:
        memory = psutil.virtual_memory()
        return jsonify({
            "status": "running", 
            "message": "AI detection server is active",
            "memory_usage": f"{memory.percent}%",
            "active_students": len(student_counters)
        })
    except Exception:
        return jsonify({"status": "running", "message": "AI detection server is active"})

@app.route('/cleanup_student', methods=['POST'])
def cleanup_student():
    """Clean up student data when exam ends"""
    try:
        data = request.get_json()
        raw = data.get('token')
        
        if not raw:
            return jsonify({"error": "Missing token"}), 400

        token = raw.split()[-1] if raw.startswith('Bearer ') else raw
        try:
            payload = jwt.decode(token, SECRET, algorithms=['HS256'])
            student_id = payload['userId']
        except jwt.ExpiredSignatureError:
            return jsonify({"error": "Token expired"}), 401
        except Exception:
            return jsonify({"error": "Invalid token"}), 401

        # Clean up student data
        if student_id in student_counters:
            del student_counters[student_id]
        
        # Clean up face mesh instance
        if student_id in face_mesh_instances:
            del face_mesh_instances[student_id]
        
        # Clean up cheat flags for this student
        keys_to_remove = [key for key in cheated_recently.keys() if key.startswith(f"{student_id}_")]
        for key in keys_to_remove:
            del cheated_recently[key]
            
        print(f"✅ Cleaned up data for student {student_id}")
        cleanup_resources()
        return jsonify({"status": "success"})
        
    except Exception as e:
        print(f"Cleanup error: {e}")
        return jsonify({"error": "Internal server error"}), 500

if __name__ == '__main__':
    print("🚀 Starting AI Detection Server...")
    try:
        print(f"📊 Available memory: {psutil.virtual_memory().available / (1024**3):.1f} GB")
    except:
        pass
    app.run(host='0.0.0.0', port=5001, threaded=True, debug=False)
